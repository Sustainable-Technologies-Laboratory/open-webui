services:
  ollama:
    volumes:
      - ollama:/root/.ollama
    container_name: ollama
#    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:${OLLAMA_DOCKER_TAG-latest}
 #   deploy:
 #     resources:
 #       reservations:
 #         devices:
 #           - driver: nvidia
 #             count: all
 #             capabilities: [gpu]
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all

  open-webui:
    build:
      context: .
      args:
        OLLAMA_BASE_URL: '/ollama'
      dockerfile: Dockerfile
#    image: ghcr.io/open-webui/open-webui:v0.6.9
    container_name: open-webui
    volumes:
      - open-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
#      - ${OPEN_WEBUI_PORT-3000}:80
       - "3000:8080"
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_SECRET_KEY=
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped

  puppeteer:
    build:
      context: ./puppeteer-in-docker
      dockerfile: Dockerfile
    ports:
      - "8081:8080"
    environment:
      NODE_ENV: "production"
      CHROMIUM_PATH: "/usr/bin/chromium"
      PORT: "8081"


volumes:
  ollama: {}
  open-webui: {}
#  puppeteer-in-docker: {}
